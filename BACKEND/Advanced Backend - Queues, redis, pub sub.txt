-------Queues, Redis and Pub Subs---------

Queues - basically when client request hits the backend server and we want to delegate a HEAVIER OR IRRELEVANT task to another worker server having a different microservice deployed in it to handle.. we push the data to a queue.
Question: we can directly push to the other server why need of Queue.
	Ans : what if there are 1000 of requests coming at same time and worker server is doing one at a time. then worker server will have to be blocked for doing one code execution at a time. Queue is better as we will have track of what is there to be executed next. 
	It is asynchronous. If worker service is down, then the task will in queue so once worker is up, it will get the data from queue directly asynchronously. 
	Can implement auto scaling of worker based on the queue length. if queue length gets more then can scale worker services more. 	
		For example, 
			1. leetcode whenever we submit the code, it delegates the code to another worker node to run. 
			2. SMS notification after a UPI transaction, can be delegated to another queue from which sms service will pull the data and send sms. 
			3. WHen we need to do heavy tasks such as video transcoding (conversion of a video into multiple qualities - 1080, 720), can push that task to queue.
				
		ex - rabitmq, sqs, redis queue. 
		
Pub-subs------------
		it can be used to push events. For example, when service worker from leetcode is done processing your code, it can publish the event to pub sub. from there, websocket can pick it up and notify client to update the user. 
	Why lot of services between worker and client ??? 
		we don't need to expose our actual worker nodes to client. the more the abstract the better. 

	Why do we need to go via PUBSUB - IN a real big application, we have lot of websocket servers - ws fleets. How do we know if ws1 has event related to a user in ws2.. We can publish it to pub sub -- example - User joining in a zoom breakout room which is geographically located in another server.

----Redis ----	High performance and low latency data. 
	open source in-memory(in RAM) data structure, used for caching and as a message broker. for caching data of database. instead of hitting db everytime, just get it from redis cache. its faster as it is an in-memory storage..data stored in-memory.
		If redis is down, can get the data from the DB. Redis can recover its data after getting up.
			REDIS CAN RECOVER THE DATA AFTER IT GETS UP. WAYS TO DO :
				1. maintain a queue of every event. if redis goes down, and gets up, we just replay every event in the queue. 
					RDB (redis database file): RDB persistence performs point in time snapshots of your redis dataset. it maintains a single compact file representation of the entire dataset.. Snapshotting process can be configured to happen at regular intervals. 
						save 900 1
						can configure to take snapshot every 900 seconds if 1 atleast key is changed.
						
				2. AOF (Append only file): AOF file logs every write operation to the redis server, appending each operation to a file.. File can be used to replay on startup to construct the dataset. 
			
		NOTE: WHAT IF VALUE CHANGES IN DATABASE, STALE DATA WILL BE IN REDIS SO AT THE TIME OF UPDATE IN DATABASE, WE WILL HAVE TO clear THE DATA IN REDIS.  so next time get api will get data from DB and store the fresh data in redis.
				have 2 more option,
					1. whenever updating can update in DB and then in redis.
					2. can first update in redis and then in DB. 		
				FROM FIRST PRINCIPLE, BOTH OPTIONS ARE WRONG. IT MAY HAPPEN THAT DB MIGHT GET DOWN AFTER UPDATING IN REDIS OR Redis might get down after updating in DB.
				FIRST PRINCIPLE : ONLY UPDATE IN ONE thing, i.e Clear redis and then update the DB. if redis fails, just send back error.. 
			
		REDIS LETS US RUN PUBS SUBS, MESSAGING QUEUES (MESSAGE BROKER)

----REDIS AS A CACHE DB------
	------normal commands----redis-cli----
	SET KEYNAME "KEYVALUE"
	GET KEYNAME 
	DEL KEYNAME
	
	---HASH GET AND HASH SET ---
	to save multiple dataset in a single keyname
	HSET user:100 name "Saurabh" email "patil.com" age "28"
	HGET user:100 name
	HGET user:100 email 
				
----REDIS AS A QUEUE-------------
	can push a topic to a redis queue and other process can pop from it. 
	We usually push from left side and pull from right side. Otherwise it will behave as stack (push from left and pull from left or push from right and pull from right only). 
 --via command line--
	LPUSH chat_message "{message: "hi", createdAt: "time"}"  // left push 
	LPUSH chat_message "{message: "I am saurabh", createdAt:"time"}"
	RPOP chat_message // will get first message.  
	BRPOP chat_message 0  		// this will blocking right pop - this will block until other process pushes onto chat_message.
								// 0 is for infinite loop unless there is a push.
								
----PUB-SUB---------------------------------------- architecture can be used for > 1 Million users.
lets backend server talk to each other. Backend server can publish an event to a pub sub server and another backend server who is a subscriber can get this event. 
	
----PUB-SUB vs Queues-----------
Both are messaging patterns for handling communication between 2 backend services. 
For Queues, we push data into queues and it gets picked up by another service. mostly order is maintained. QUEUES ARE SUITABLE WHERE WE NEED ORDERED MESSAGE DELIVERY, POINT TO POINT COMMUNICATION. ONE TO ONE COMMUNICATION.
	USECASE: SUITABLE FOR ORDERING SYSTEMS. sequential data processing. 
For PUB-SUB, Messages are published on a topic instead of being sent to a queue and the services which have subscribed to that topic will get the published message. ONE TO MANY OR MANY TO MANY COMMUNICATION. FOR BROADCASTING REAL TIME UPDATES, NOTIFICATION.
	USECASE: Live updates, news feed. 
		client.publish(channel,message) // client.subscribe(channel , (callbackFn) => {})