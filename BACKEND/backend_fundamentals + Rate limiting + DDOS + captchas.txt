backend is divided into 4 things :
HTTP servers, authentication, databases and middleware.

SERVERLESS - BACKEND DEPLOYMENT where cloud providers does the provisioning and management of the servers.
Pros - autoscaling -- when we have low traffic and optimize for costs. 
cons -- 1. Serverless is very expensive at scale.. as will have to pay per request.. at Facebook level, very expensive. will have switch to VMs architecture.
2. Cold start problem - if there is no traffic then server will be stopped.. but if suddenly after sometime if someone hits the site, it will take some time to start the service. 
	can have a warm pool - configure some set of server to be always up even if there's no traffic. 
--Famous serverless providers - AWS Lambda, Google cloud functions, Cloudfare workers.

Cloudfare workers - we create a worker - basically a function that will run on the cloud. They don't use nodejs runtime. they have some other runtime. Cloudfare worker - Own JS Runtime - basically a compiler associate. 
	They used v8 to create their own runtime. Worker functions run on cloudfare edge network - global network of thousands of machines distributed across the world. 
	They claim faster than AWS - V8 orchestrate isolates - which is lightweight contexts that provide our code a safe environment with variables it can access and be executed within. 	basically instead of multiple index.js for every nodejs process. a single index.js will call multiple nodejs processes... basically a routing. 
	A SINGLE RUNTIME CAN RUN THOUSANDS OF ISOLATES and can context switch between them. isolate's memory is completed isolated. they are designed to start quickly solving the problem of COLD START. INSTEAD OF CREATING VM FOR EACH FUNCTION, ISOLATE IS CREATED WITHIN AN EXISTING ENV. 
	
	npm create cloudfare -- my-app
	npm create cloudflare@latest
	
	wrangler - is the CLI for the cloudfare. creating an http server on top of the worker function is handled by wrangler. 
			can configure our own CI CD using wrangler. 
	Cannot use express in cloudfare worker functions.  WE CAN USE HONO - ROUTING framework SIMILAR TO EXPRESS for cloudfare AS CLOUDFARE DOESN'T SUPPORT EXPRESSJS..

to resolve dns names in ec2/vm in aws, we have to edit /etc/resolv.conf --> nameserver 8.8.8.8.
NOTE: NEVER PUT LISTEN OF NODEJS ON PORT 80 OR 443. 

VERCEL IS EXPENSIVE ON SCALE. AWS IS CHEAPER. 

whatever we don't store on databases, like images, media files..we store them as objects.  WE STORE THEM IN OBJECT STORES. 
AWS HAS S3 - SIMPLE STORAGE SERVICE
direct access to files url from S3 is a bad practice. 



PREFLIGHT REQUEST  is a CORS MECHANISM OF BROWSER - HTTP REQUEST made by browser to check if its safe to send the actual request. TO DETERMINE IF THE REQUEST (METHOD - GET, POST, PUT, DELETE) IS allowed by server or not. 
	checks whether this request is allowed is not.. its usually cached to make it faster. 


BACKEND ENGINEERING FUNDAMENTALS ---

1. communication protocols - TCP VS UDP. 
tcp is stream based connectioned oriented protocol. UDP IS message based and connectionless. 
TCP provides reliable delivery at cost of retransmission and connection setup while UDP travels faster but doesn't guarantee delivery.
tcp is not better and neither is udp better than tcp. it all depends on anything that we build on top of these protocol.

MOVING up the stack, http is based on tcp as we wanted to send requests and responses reliably. as web evolved, one connection was not sufficient to enough to send multiple requests. http/2 introduced application level streams so multiple requests can be processed on the same connection. 
Http/2 might give more request throughput, but was causing higher CPUs load. 
Later http/2 evolved and written on top of UDP with http/3. 
Sometimes a backend architecture required bidirectional communication protocol for building chatting, gaming apps. Protocols such a websockets, Grpc or just raw TCP/UDP can be used.


2. Web servers - web servers delivers static or dynamic content served on top of HTTP protocol. if we build own web server, can use express/django. 
configuring web server with appropriate protocol is important. most web servers support http/1.1 and http/2. http/3 is slowly getting support. 
Http/2 is good for multiplexing -- multiple  concurrent request handling. 
web servers can be single threaded or multithreaded. can have one thread or multiple thread listener. web server can set anywhere in the stack.. for e.g, CDN is web server that acts like a cache & communicate with origin backend web server to get the content.  can build own server by listening to a TCP port ... (expressjs)

3. database engineering. 
allow multiple users to store and retrieve data consistently. can use redis for caching. understanding 4 properties of ACID -  atomicity, consistency, isolation and  durability. 
No database is complete without indexes & at their core B+ TREE is Data structure of choice. 
graphs end up as file system pages 

4. Proxies - it receives requests from clients and forwards the request to backend. it hides the network layer identity of original client from the destination server. 2 levels of proxying - layer 4 and layer 7. Layer 4 proxying works at transport layer and layer 7 works at application level.
Each layer provides different capabilities & can be used for different purposes.
Layer 7 proxying requires proxy to understand application level while Layer 4 can work with any application as it works with transport layer (TCP/UDP)

	FORWARD PROXY - client asks for a particular backend server & proxy fulfills his request. forward proxy must be configured in client network. 
		Forward proxy - sits in front of client. Before sending the request to the internet resource, then on behalf of the client, forward proxy send the requests.   
			example - Client anonymity, logging, traffic control. 
	REVERSE PROXY - client doesn't know final backend server. 
		Reverse proxy sits in front of the one or more web server. Reverse proxy receives the response from web server and then it forwards to the client. 
			example - load balancing.server anonymity. 					
	
	Proxy - before you hit the final service. you go through a proxy .. a filter basically in college we are not able to access certain sites.. so any request we do is first hit on the proxy and then through that it is filtered we have to go the other site or not.. 
	Reverse Proxy - when we hit the backend server it then identifies where to route and then routes to that particular backend server. 
	
  USE CASES OF PROXYING - caching, API gateways, authentication, load balancing.  CDN is reverse proxy which sends request back to the origin backends.

5. Messaging systems -  As multiple services starts communicating, coupling and dependencies might increase which might increase complexity of backend systems. so Messaging systems come to the rescue to remove this coupling. 
PUBLISH - SUBSCRIBE FEATURE - client can publish a message and other clients can subscribe to consume that content.  CHOICE OF ARCHITECTING HOW PUBLISHING AND SUBSCRIBING HAPPENS DEPENDS ON MESSAGING SYSTEM.... KAFKA USE LONG-POLLING MODEL WHERE RABITMQ USES PUSH MODEL. 

6. Message formats - message formats go hand in hand with communication protocols. e.g, XML, JSON. When client sends a message to backend , it needs to serialize the message and when backend receives then deserialize the message from this format to the language data structure. 
NOTE : IT IS IMPORTANT TO UNDERSTAND THE COST OF SERIALIZING AND DESERIALIZING. 
	XML WAS FIRST ONE BUT COMPUTERS HAD DIFFICULTY reading it so protocol buffer was created to make message format smaller and minimize the payload & for speeding up serialization and deserializing. 
	
7. Security - can secure connection with TLS or encryption.  TLS TO PREVENT  man in the middle attack. this is where attacker intercepts communication between two parties & tries to eavesdrop or modify the data. 

SSH - secure shell - tunneling connection into the system..
IPs cannot be more than 255.255.255.255
-----------------------------------------------NGINX------------------------------
open source software for web server , reverse proxying, caching, load balancing, media based streaming - RTMP module.
WHILE LOAD BALANCERS BALANCE ACROSS MACHINES, REVERSE PROXY BALANCE ACROSS PROCESSES IN SAME MACHINE. 
to configure reverse proxy for nginx.. : 
		/etc/nginx/nginx.conf - 
		http {
		server  {
		listen 80;
		server_name be1.app.com; // url
		location / {
			proxy_pass http:localhost:8080  // where to route. 
			}
			
		}	}
	to restart nginx - sudo nginx -s reload. 
	
TO ALLOW INTERNET ACCESS IN LINUX :
	/etc/resolv.conf 
	
		nameserver 8.8.8.8
		nameserver 8.8.4.4

----------------------DOCKER-------------------------
DOCKER HAS TO BE MAPPED A PORT FROM OUR LOCAL MACHINE TO THE PROCESS RUNNING IN DOCKER .. FOR EXAMPLE.
	MONGODB - docker run -d -p 27017:27017 mongo -- maps local port to the mongodb running in the docker.  	
			-d - detached mode to run in background mode. 
	docker ps - to list containers.
	docker kill container_id
	
	POSTGRES - docker run -e POSTGRES_PASSWORD=mysecretpassword -d -p 5432:5432 postgres
	

--------------------Rate limiting---------------------
It happens at code level : hits backend code but gets thrown out. 
At Load balancer/API gateway level, without hitting backend, gets thrown out. 
Its used for preventing overloads, mitigating abuse, handling traffic, ddos protection, brute force attacks. 

WE do rate limiting based on IPs and user_ids. e.g in college campuses, requests are mmostly proxied through a central server(common ip) which can hit the rate limit so users id rate limiting is better in this scenario. 

NOTE: Rate limiting isn't AFFECTIVE FOR DDOS ATTACKS as it comes from multiple sources  (distributed attack - multiple ips) 
	Some APIs can be heavily rate limited for their their security for example - otp service, forgot password, payment api. some can be loosely rate limited..for example - 100 reqs per 30 second..
	
--express-rate-limiter-- can be used to implement rate limiting. 
		
		const limiter = rateLimit({
			windowMs: 15 * 60 * 1000, // 15 minutes
			limit: 100, // Limit each IP to 100 requests per `window` (here, per 15 minutes).
			standardHeaders: 'draft-7', // draft-6: `RateLimit-*` headers; draft-7: combined `RateLimit` header
			legacyHeaders: false, // Disable the `X-RateLimit-*` headers.
			// store: ... , // Redis, Memcached, etc. See below.
		})
		app.use(limiter)	// to apply rate limiter to all apis.
		
		app.get("/verifyOTP", limiter, (req,res))  	// to apply rate limiter for one api only. 
		
----------------------DDOS-------------------------------distributed denial of service
after rate limiting also, backend is vulnerable to DDOS attacks as its distributed. its to deny service to original users by oberloading with loads of requests. 

One of the ways to prevent DDOS is use proxy service before hitting the api, it will hit the proxy service which will check if the request is legit. 
	for example cloudflare ddos protection service, AWS Sheild, GCP - WAF
	Basic requirement for cloudflare ddos is to buy domain from cloudlare and map the domain with ipv4 address and get it proxied.
		Basically every request which hits our backend will go through this cloudflare proxy which will check if its a ddos attack. 
		
---------------------CAPTCHA-----------------------------
Captcha is one of the way to prevent ddos attack. After a request reaches the server, to verify if the request is legit request , we use captcha. can integrate captcha using CLOUDFLARE TURNSTILE. IN CLOUDFLARE, WE GIVE IT DOMAIN NAME AND WE GENERATE SITE KEY AND SECRET KEY. 
	FLOW: 
		When a user visits a site with captcha, they are thrown few challenges to verify if the user is not a robot.
		If a user passes this challenge, cloudflare workers create a token and that token should be sent to backend who will verify if the token is valid from cloudflare. if yes, it will allow client to do further processing. 
	Implementation:
		in UI we use turnstile component which requires 2 props - (public) siteKey and onSuccess method which has to be supplied a callback function to store token.
		in backend, we get the token and verify it by sending it to cloudflare api. this api requires secret key and token appended to formData.
			
--------Authenticator protocol---------------
	It can be a function of user id , current time and secret key.. so otp can be generated using this and can be send to gmail. 
	then while verifying, user can input the otp (received in mail). same function can be called in backend to verify if same otp is being generated or not. THIS WAY WE CAN IMPLEMENT 2 FACTOR AUTHENTICATION. 